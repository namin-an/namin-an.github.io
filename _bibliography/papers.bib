---
---

@article{an2024capturing,
  title={Capturing the Relationship Between Sentence Triplets for LLM and Human-Generated Texts to Enhance Sentence Embeddings},
  author={An, Na Min and Waheed, Sania and Thorne, James},
  journal={Findings of the 2024 European Chapter of the Association for Computational Linguistics},
  year={2024}}
}

@inproceedings{lee-etal-2023-large,
    title = "Can Large Language Models Capture Dissenting Human Voices?",
    author = "Lee, Noah$*$  and
      An, Na Min$*$  and
      Thorne, James",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.278",
    doi = "10.18653/v1/2023.emnlp-main.278",
    pages = "4569--4585",
    arxiv = "https://aclanthology.org/2023.emnlp-main.278",
    abstract = "Large language models (LLMs) have shown impressive achievements in solving a broad range of tasks. Augmented by instruction fine-tuning, LLMs have also been shown to generalize in zero-shot settings as well. However, whether LLMs closely align with the human disagreement distribution has not been well-studied, especially within the scope of natural language inference (NLI). In this paper, we evaluate the performance and alignment of LLM distribution with humans using two different techniques to estimate the multinomial distribution: Monte Carlo Estimation (MCE) and Log Probability Estimation (LPE). As a result, we show LLMs exhibit limited ability in solving NLI tasks and simultaneously fail to capture human disagreement distribution. The inference and human alignment performances plunge even further on data samples with high human disagreement levels, raising concerns about their natural language understanding (NLU) ability and their representativeness to a larger human population.",
    note = {$*$ indicates equal contribution.}}
}

@INPROCEEDINGS{10191870,
  author={An, Na Min and Roh, Hyeonhee and Kim, Sein and Kim, Jae Hun and Im, Maesoon},
  booktitle={2023 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Reinforcement Learning Framework to Simulate Short-Term Learning Effects of Human Psychophysical Experiments Assessing the Quality of Artificial Vision}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/IJCNN54540.2023.10191870},
  url={https://ieeexplore.ieee.org/document/10191870}}

@misc{maesoon2023artificial,
  title={Artificial Vision Parameter Learning and Automating Method for Improving Visual Prosthetic Systems},
  author={Im, Maesoon and Roh, Hyeonhee and An, Na Min and Kim, Jae Hun},
  year={2023},
  month=jun # "~8",
  publisher={Google Patents},
  note={US Patent App. 18/075,555}}

@article{an2021machine,
  title={Machine Learning Approaches as An Alternative to Human Psychophysical Tests of Prosthetic Vision (abstract)},
  author={An, Na Min and Roh, Hyeonhee and Jung, Soomin and Kim, Eun Ju and Im, Maesoon},
  journal={2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)},
  year={2021},
  url={https://paperhost.org/proceedings/embs/EMBC21/files/2302.pdf}}